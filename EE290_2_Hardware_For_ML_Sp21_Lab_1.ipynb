{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE290-2: Hardware For ML - Sp21 - Lab 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franceshe/Research/blob/master/EE290_2_Hardware_For_ML_Sp21_Lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTvIwDlYvBzC"
      },
      "source": [
        "# Initial Setup\n",
        "\n",
        "Before beginning the assignment, we import the CIFAR dataset, and train a simple convolutional neural network (CNN) to classify it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbiiMcdNJI--"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG3WW1Owq1Fh"
      },
      "source": [
        "**Reminder:** set the runtime type to \"GPU\", or your code will run much more slowly on a CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3RF5VmcoUMG"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCaMDWYArEXO"
      },
      "source": [
        "Load training and test data from the CIFAR10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5UuOjjrnogR"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l62CkyIwtSOv"
      },
      "source": [
        "Define a simple CNN that classifies CIFAR images.\n",
        "The network provided is similar to LeNet-5, and it has the following architecture:\n",
        "\n",
        "**Layer** | **Type** | **Input Shape** | **Output Shape** | **Activation**\n",
        "--- | --- | --- | --- | ---\n",
        "conv1 | Convolutional | 3x32x32 | 6x28x28 | ReLU \n",
        "pool1 | Max pool | 6x28x28 | 6x14x14 | None                \n",
        "conv2 | Convolutional | 6x14x14 | 16x10x10 | ReLU                \n",
        "pool2 | Max pool | 16x10x10 | 16x5x5 | None                \n",
        "fc1 | Fully-connected | 400 | 120 | ReLU                \n",
        "fc2 | Fully-connected | 120 | 84 | ReLU                \n",
        "fc3 | Fully-connected | 84 | 10 | None                \n",
        "\n",
        "None of the layers in the network have a bias associated with them.\n",
        "This makes them easier to quantize.\n",
        "Towards the end of this assignment, we will add biases to the final layer and quantize it as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fL3F-7Rntog"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, bias=False)\n",
        "        self.pool = nn.MaxPool2d(2, 2) # run after each conv (hence the 5x5 FC layer)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120, bias=False)\n",
        "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
        "        self.fc3 = nn.Linear(84, 10, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nijieuxptag6"
      },
      "source": [
        "Train this CNN on the training dataset (this may take a few moments)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzK6ohj5oNCT"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train(model: nn.Module, dataloader: DataLoader):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "def test(model: nn.Module, dataloader: DataLoader, max_samples=None) -> float:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    n_inferences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images) # get 1 batch worth of image predictions (i.e. 4 predictions of 10 each)\n",
        "            other, predicted = torch.max(outputs.data, 1) # other == values, predicted == indicies\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if max_samples:\n",
        "                n_inferences += images.shape[0]\n",
        "                if n_inferences > max_samples:\n",
        "                    break\n",
        "    \n",
        "    return 100 * correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HixhBHaqtmZU"
      },
      "source": [
        "train(net, trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJggxnCVuRxU"
      },
      "source": [
        "Now that the CNN has been trained, let's test it on our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y27_n-djuEdz"
      },
      "source": [
        "score = test(net, testloader)\n",
        "print('Accuracy of the network on the test images: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-GbgOYpjamn"
      },
      "source": [
        "Define a convenience function which we use to copy CNN's."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVWbC5YWT-MU"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def copy_model(model: nn.Module) -> nn.Module:\n",
        "    result = deepcopy(model)\n",
        "\n",
        "    # Copy over the extra metadata we've collected which copy.deepcopy doesn't capture\n",
        "    if hasattr(model, 'input_activations'):\n",
        "        result.input_activations = deepcopy(model.input_activations)\n",
        "\n",
        "    for result_layer, original_layer in zip(result.children(), model.children()):\n",
        "        if isinstance(result_layer, nn.Conv2d) or isinstance(result_layer, nn.Linear):\n",
        "            if hasattr(original_layer.weight, 'scale'):\n",
        "                result_layer.weight.scale = deepcopy(original_layer.weight.scale)\n",
        "            if hasattr(original_layer, 'activations'):\n",
        "                result_layer.activations = deepcopy(original_layer.activations)\n",
        "            if hasattr(original_layer, 'output_scale'):\n",
        "                result_layer.output_scale = deepcopy(original_layer.output_scale)\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQZoEjBSveV8"
      },
      "source": [
        "# Question 1: Visualize Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap_PBg9Pjll_"
      },
      "source": [
        "## Question 1.1:\n",
        "\n",
        "Plot histograms of the weights of every convolutional and fully-connected layer. Record any observations you make about the distribution of the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qKRX7ply7I2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2h7zJ8m3GAF"
      },
      "source": [
        "# ADD YOUR CODE HERE to plot distributions of weights\n",
        "\n",
        "# You can get a flattened vector of the weights of fc1 like this:\n",
        "#   fc1_weights = net.fc1.weight.data.cpu().view(-1)\n",
        "# Try plotting a histogram of fc1_weights (and the weights of all the other layers as well)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmJEtoCgkLYn"
      },
      "source": [
        "## Question 1.2:\n",
        "\n",
        "Record the range of the weights, as well as their 3-sigma range (the difference between $\\mu + 3\\sigma$ and $\\mu - 3\\sigma$).\n",
        "For which layers is the 3-sigma range larger or smaller than the actual range?\n",
        "Then explain which range you would prefer to use if you were to quantize each layer's weights and wanted to strike a balance between the range of values that could be expressed, and your precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh75YXIXkH57"
      },
      "source": [
        "# ADD YOUR CODE HERE to record the range of the weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hKjshaHD11m"
      },
      "source": [
        "# Question 2: Quantize Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueJLirORlFbQ"
      },
      "source": [
        "Any convolution or fully-connected layer pass, without a bias, can be described by the equation:\n",
        "\n",
        "$$W*In = Out$$\n",
        "\n",
        "where $W$ is the weight tensor, $In$ in the input tensor, and $Out$ is the output tensor.\n",
        "\n",
        "For this question, your task is to find a *scaling factor*, called $n_W$ for each convolutional and fully connected layer,\n",
        "which would fit inside an 8-bit signed integer.\n",
        "This equation can now be described as the following:\n",
        "\n",
        "$$n_WW*In = n_WOut$$\n",
        "\n",
        "You might wonder: \"Isn't it a problem that the output of the layer has now changed? Wouldn't quantizing the weights change the output of the neural net?\"\n",
        "\n",
        "The answer, of course, is: \"Yes\".\n",
        "However, what we care about is not the *absolute* values output by the CNN, but the relative difference between the probabilities it assigns to different classes for its predictions.\n",
        "Quantizing the weights only scales this relative difference up or down, but it does not affect which class the network assigns the most probability to.\n",
        "Therefore, it does not affect the final predictions that the neural net makes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WVKWshdmuvm"
      },
      "source": [
        "Copy the old model into a new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXNk1fXuPGjB"
      },
      "source": [
        "net_q2 = copy_model(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_L9Yv0Wm7Zo"
      },
      "source": [
        "## Question 2.1:\n",
        "\n",
        "Fill in the `quantized_weights` function.\n",
        "The template code we provide will then call this function on the weights of every layer in the CNN that we just trained at 32-bit floating point precision, to lower them into 8-bit signed integer precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIBrqSFrVi5x"
      },
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def quantized_weights(weights: torch.Tensor) -> Tuple[torch.Tensor, float]:\n",
        "    '''\n",
        "    Quantize the weights so that all values are integers between -128 and 127.\n",
        "    You may want to use the total range, 3-sigma range, or some other range when\n",
        "    deciding just what factors to scale the float32 values by.\n",
        "\n",
        "    Parameters:\n",
        "    weights (Tensor): The unquantized weights\n",
        "\n",
        "    Returns:\n",
        "    (Tensor, float): A tuple with the following elements:\n",
        "                        * The weights in quantized form, where every value is an integer between -128 and 127.\n",
        "                          The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
        "                        * The scaling factor that your weights were multiplied by.\n",
        "                          This value does not need to be an 8-bit integer.\n",
        "    '''\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "    scale = 2.5\n",
        "    return torch.clamp(result, min=-128, max=127), scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orOwTnXxU1nb"
      },
      "source": [
        "def quantize_layer_weights(model: nn.Module):\n",
        "    for layer in model.children():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            q_layer_data, scale = quantized_weights(layer.weight.data)\n",
        "            q_layer_data = q_layer_data.to(device)\n",
        "\n",
        "            layer.weight.data = q_layer_data\n",
        "            layer.weight.scale = scale\n",
        "\n",
        "            if (q_layer_data < -128).any() or (q_layer_data > 127).any():\n",
        "                raise Exception(\"Quantized weights of {} layer include values out of bounds for an 8-bit signed integer\".format(layer.__class__.__name__))\n",
        "            if (q_layer_data != q_layer_data.round()).any():\n",
        "                raise Exception(\"Quantized weights of {} layer include non-integer values\".format(layer.__class__.__name__))\n",
        "\n",
        "quantize_layer_weights(net_q2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah_IkrjhnXAM"
      },
      "source": [
        "## Question 2.2:\n",
        "\n",
        "Record the accuracy change of the network after quantizing its weights. \n",
        "If you’ve done everything correctly, the accuracy change should be negligible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE3HqeBKVoYR"
      },
      "source": [
        "score = test(net_q2, testloader)\n",
        "print('Accuracy of the network after quantizing all weights: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg7bfTF1bBVe"
      },
      "source": [
        "# Question 3: Visualize Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODLMJ6DznjFa"
      },
      "source": [
        "Now that we have quantized the weights of the CNN, we must also quantize the activations (inputs and outputs to layers) traveling through it.\n",
        "But before doing so, let's analyze what values the activations take when travelling through the network.\n",
        "\n",
        "We provide convenience code which will record the values of every pixel of the outputs and inputs travelling through the neural network.\n",
        "(This is the initial CNN, where not even the weights had yet been quantized).\n",
        "We then profile these values when running on a subset of the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP587b0QYxe9"
      },
      "source": [
        "def register_activation_profiling_hooks(model: Net):\n",
        "    model.input_activations = np.empty(0)\n",
        "    model.conv1.activations = np.empty(0)\n",
        "    model.conv2.activations = np.empty(0)\n",
        "    model.fc1.activations = np.empty(0)\n",
        "    model.fc2.activations = np.empty(0)\n",
        "    model.fc3.activations = np.empty(0)\n",
        "\n",
        "    model.profile_activations = True\n",
        "\n",
        "    def conv1_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.input_activations = np.append(model.input_activations, x[0].cpu().view(-1))\n",
        "    model.conv1.register_forward_hook(conv1_activations_hook)\n",
        "\n",
        "    def conv2_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.conv1.activations = np.append(model.conv1.activations, x[0].cpu().view(-1))\n",
        "    model.conv2.register_forward_hook(conv2_activations_hook)\n",
        "\n",
        "    def fc1_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.conv2.activations = np.append(model.conv2.activations, x[0].cpu().view(-1))\n",
        "    model.fc1.register_forward_hook(fc1_activations_hook)\n",
        "\n",
        "    def fc2_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.fc1.activations = np.append(model.fc1.activations, x[0].cpu().view(-1))\n",
        "    model.fc2.register_forward_hook(fc2_activations_hook)\n",
        "\n",
        "    def fc3_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.fc2.activations = np.append(model.fc2.activations, x[0].cpu().view(-1))\n",
        "            model.fc3.activations = np.append(model.fc3.activations, y[0].cpu().view(-1))\n",
        "    model.fc3.register_forward_hook(fc3_activations_hook)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnpV3LUZnxtv"
      },
      "source": [
        "Use the unquantized model to profile input and output activations on a subset of the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVvPCIoabLC7"
      },
      "source": [
        "net_q3 = copy_model(net)\n",
        "register_activation_profiling_hooks(net_q3)\n",
        "\n",
        "# Run through the training dataset again while profiling the input and output activations this time\n",
        "# We don't actually have to perform gradient descent for this, so we can use the \"test\" function\n",
        "test(net_q3, trainloader, max_samples=400)\n",
        "net_q3.profile_activations = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1HnYsuAMoxP"
      },
      "source": [
        "input_activations = net_q3.input_activations\n",
        "conv1_output_activations = net_q3.conv1.activations\n",
        "conv2_output_activations = net_q3.conv2.activations\n",
        "fc1_output_activations = net_q3.fc1.activations\n",
        "fc2_output_activations = net_q3.fc2.activations\n",
        "fc3_output_activations = net_q3.fc3.activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDP__SFRoAdh"
      },
      "source": [
        "## Question 3.1:\n",
        "\n",
        "Plot histograms of the input images and the outputs of every convolutional and fully-connected layer. \n",
        "Record any observations you make about the distribution of the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEo8VK46bwjn"
      },
      "source": [
        "# ADD YOUR CODE HERE to plot distributions of activations\n",
        "\n",
        "# Plot histograms of the following variables, and calculate their ranges and 3-sigma ranges:\n",
        "#   input_activations\n",
        "#   conv1_output_activations\n",
        "#   conv2_output_activations\n",
        "#   fc1_output_activations\n",
        "#   fc2_output_activations\n",
        "#   fc3_output_activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDdjK8teoWXS"
      },
      "source": [
        "## Question 3.2:\n",
        "\n",
        "Additionally, record the range of the values, as well as their 3-sigma range (the difference between $\\mu + 3\\sigma$ and $\\mu - 3\\sigma$).\n",
        "For which layers is the 3-sigma range larger or smaller than the actual range?\n",
        "Then explain which range you would prefer to use if you were to quantize each layer's weights and wanted to strike a balance between the range of values that could be expressed, and your precision.\n",
        "Remember that you are plotting the activations *after* activation functions like ReLU have been applied, which means that you should not be worried if you find that your plots are asymmetric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-7K7zjKoVVO"
      },
      "source": [
        "# ADD YOUR CODE HERE to record the range of the weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haiPVx4ibEra"
      },
      "source": [
        "# Question 4: Quantize Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCNDSAltowM8"
      },
      "source": [
        "Now it is time to quantize the activations (inputs and outputs to layers) traveling through the CNN.\n",
        "Our equation now becomes:\n",
        "\n",
        "$$n_WW*n_{In}In*n_{Out} = n_Wn_{In}n_{Out}Out$$\n",
        "\n",
        "where $n_{In}$ is the scaling factor which was applied to the input to the layer, and $n_{Out}$ is the scaling factor which we decide to apply to the output of the layer.\n",
        "$n_{Out}$ must be chosen such that the expected values of the elements of $Out$ can be scaled down to fit within 8 bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE95vE5opICC"
      },
      "source": [
        "## Question 4.1:\n",
        "\n",
        "Before performing any quantization at all, we could describe the output of the `conv1` layer as:\n",
        "\n",
        "$$W_{conv1} * In = Out_{conv1}$$\n",
        "\n",
        "Suppose that we quantized the input matrix, $In$, scaling it down by $n_{In}$.\n",
        "Suppose that we also scaled the weight matrix, $W_{conv1}$, by $n_{W_{conv1}}$, and the output matrix, $Out_{conv1}$, by $n_{Out_{conv1}}$.\n",
        "\n",
        "In the lab report answer the following sub-questions for **4.1.**:\n",
        "\n",
        "**(a)** Write an equation describing the output of the `conv1` layer with these new scaling parameters.\n",
        "\n",
        "**(b)** Write an equation describing the output of the `conv2` layer in terms of $In$, $W_{conv1}$, $W_{conv2}$, $Out_{conv1}$, $Out_{conv2}$, $n_{In}$, $n_{W_{conv1}}$, $n_{W_{conv2}}$, $n_{Out_{conv1}}$, and $n_{Out_{conv2}}$.\n",
        "You can pretend that the pooling layers do not exist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVTwOGR3p8Qu"
      },
      "source": [
        "## Question 4.2:\n",
        "\n",
        "Complete the `quantize_initial_input` and `quantize_activations` functions which calculate the scaling factors for the initial image which is input to the CNN, and the outputs of each layer, respectively.\n",
        "\n",
        "## Question 4.3:\n",
        "\n",
        "Complete the `forward` function for the `NetQuantized` class.\n",
        "You will have to add code here to scale the outputs of each layer, and then to clamp the outputs of each layer to integers between -128 and 127 afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLjSp7hsXofq"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "class NetQuantized(nn.Module):\n",
        "    def __init__(self, net_with_weights_quantized: nn.Module):\n",
        "        super(NetQuantized, self).__init__()\n",
        "        \n",
        "        net_init = copy_model(net_with_weights_quantized)\n",
        "\n",
        "        self.conv1 = net_init.conv1\n",
        "        self.pool = net_init.pool\n",
        "        self.conv2 = net_init.conv2\n",
        "        self.fc1 = net_init.fc1\n",
        "        self.fc2 = net_init.fc2\n",
        "        self.fc3 = net_init.fc3\n",
        "\n",
        "        for layer in self.conv1, self.conv2, self.fc1, self.fc2, self.fc3:\n",
        "            def pre_hook(l, x):\n",
        "                x = x[0]\n",
        "                if (x < -128).any() or (x > 127).any():\n",
        "                    raise Exception(\"Input to {} layer is out of bounds for an 8-bit signed integer\".format(l.__class__.__name__))\n",
        "                if (x != x.round()).any():\n",
        "                    raise Exception(\"Input to {} layer has non-integer values\".format(l.__class__.__name__))\n",
        "\n",
        "            layer.register_forward_pre_hook(pre_hook)\n",
        "\n",
        "        # Calculate the scaling factor for the initial input to the CNN\n",
        "        self.input_activations = net_with_weights_quantized.input_activations\n",
        "        self.input_scale = NetQuantized.quantize_initial_input(self.input_activations)\n",
        "\n",
        "        # Calculate the output scaling factors for all the layers of the CNN\n",
        "        preceding_layer_scales = []\n",
        "        for layer in self.conv1, self.conv2, self.fc1, self.fc2, self.fc3:\n",
        "            layer.output_scale = NetQuantized.quantize_activations(layer.activations, layer.weight.scale, self.input_scale, preceding_layer_scales)\n",
        "            preceding_layer_scales.append((layer.weight.scale, layer.output_scale))\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_initial_input(pixels: np.ndarray) -> float:\n",
        "        '''\n",
        "        Calculate a scaling factor for the images that are input to the first layer of the CNN.\n",
        "\n",
        "        Parameters:\n",
        "        pixels (ndarray): The values of all the pixels which were part of the input image during training\n",
        "\n",
        "        Returns:\n",
        "        float: A scaling factor that the input should be multiplied by before being fed into the first layer.\n",
        "               This value does not need to be an 8-bit integer.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        return 1.0 \n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_activations(activations: np.ndarray, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]]) -> float:\n",
        "        '''\n",
        "        Calculate a scaling factor to multiply the output of a layer by.\n",
        "\n",
        "        Parameters:\n",
        "        activations (ndarray): The values of all the pixels which have been output by this layer during training\n",
        "        n_w (float): The scale by which the weights of this layer were multiplied as part of the \"quantize_weights\" function you wrote earlier\n",
        "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
        "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
        "\n",
        "        Returns:\n",
        "        float: A scaling factor that the layer output should be multiplied by before being fed into the first layer.\n",
        "               This value does not need to be an 8-bit integer.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        return 1.0 \n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # You can access the output activation scales like this:\n",
        "        #   fc1_output_scale = self.fc1.output_scale\n",
        "\n",
        "        # To make sure that the outputs of each layer are integers between -128 and 127, you may need to use the following functions:\n",
        "        #   * torch.Tensor.round\n",
        "        #   * torch.clamp\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        return torch.Tensor([[1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                             [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                             [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                             [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).to(device)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13CpHgvE994J"
      },
      "source": [
        "# Merge the information from net_q2 and net_q3 together\n",
        "net_init = copy_model(net_q2)\n",
        "net_init.input_activations = deepcopy(net_q3.input_activations)\n",
        "for layer_init, layer_q3 in zip(net_init.children(), net_q3.children()):\n",
        "    if isinstance(layer_init, nn.Conv2d) or isinstance(layer_init, nn.Linear):\n",
        "        layer_init.activations = deepcopy(layer_q3.activations)\n",
        "\n",
        "net_quantized = NetQuantized(net_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrMRIDDhqiWl"
      },
      "source": [
        "## Question 4.4:\n",
        "\n",
        "Finally, record the accuracy of your network after both weights and activations have been quantized.\n",
        "If you've done everything right, you should still find almost no accuracy change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcBXEodN6hrY"
      },
      "source": [
        "score = test(net_quantized, testloader)\n",
        "print('Accuracy of the network after quantizing both weights and activations: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jTOL7scbMs7"
      },
      "source": [
        "# Question 5: Quantize Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnTajSR6qpvZ"
      },
      "source": [
        "Let us now update our CNN to include a bias in its final layer, *fc3*.\n",
        "We have already included code to create and train a new CNN called `net_with_bias`.\n",
        "\n",
        "Consider how a bias affects the equation for an unquantized layer:\n",
        "\n",
        "$$W * In + \\beta = Out$$\n",
        "\n",
        "where $\\beta$ is the bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVF-HrHTrCQ4"
      },
      "source": [
        "## Question 5.1:\n",
        "\n",
        "Suppose that we again quantized a biased layer with the same scaling factors we used in previous questions: $n_W$, $n_{In}$, and $n_{Out}$.\n",
        "What would we scale $\\beta$ by in this case?\n",
        "Write an equation in your lab report to describe the output of the quantized layer with a bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DSlteOIrW4n"
      },
      "source": [
        "Create a new network with a bias on *fc3*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvv9-k1HPbgz"
      },
      "source": [
        "class NetWithBias(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetWithBias, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, bias=False)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120, bias=False)\n",
        "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
        "        self.fc3 = nn.Linear(84, 10, bias=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net_with_bias = NetWithBias().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwEA1Scirfgd"
      },
      "source": [
        "Train and score the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjk3hEQaVDpq"
      },
      "source": [
        "train(net_with_bias, trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vLUCDnnVf4R"
      },
      "source": [
        "score = test(net_with_bias, testloader)\n",
        "print('Accuracy of the network (with a bias) on the test images: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfgx1kC9rpIB"
      },
      "source": [
        "Test the network with quantized weights but unquantized bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_ZiJk6yEEM-"
      },
      "source": [
        "register_activation_profiling_hooks(net_with_bias)\n",
        "test(net_with_bias, trainloader, max_samples=400)\n",
        "net_with_bias.profile_activations = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZwk8KLtAUAM"
      },
      "source": [
        "net_with_bias_with_quantized_weights = copy_model(net_with_bias)\n",
        "quantize_layer_weights(net_with_bias_with_quantized_weights)\n",
        "\n",
        "score = test(net_with_bias_with_quantized_weights, testloader)\n",
        "print('Accuracy of the network on the test images after all the weights are quantized but the bias isn\\'t: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1apkXYsdrvBD"
      },
      "source": [
        "## Question 5.2:\n",
        "\n",
        "Fill in the `quantized_bias` function in the `NetQuantizedWithBias` class.\n",
        "This function is meant to quantize the bias on the final layer of the CNN.\n",
        "Keep in mind that biases are typically quantized to 32-bits, so your bias values do not all have to be between -128 and 127 (though 32-bits is a bit conservative)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULnpgyBNw-Qo"
      },
      "source": [
        "# slightly clearer bias bounds (32b signed integer)\n",
        "MIN_32B_SINT = -(2**31)\n",
        "MAX_32B_SINT = (2**31) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO2Gdu_tEZ4v"
      },
      "source": [
        "class NetQuantizedWithBias(NetQuantized):\n",
        "    def __init__(self, net_with_weights_quantized: nn.Module):\n",
        "        super(NetQuantizedWithBias, self).__init__(net_with_weights_quantized)\n",
        "\n",
        "        preceding_scales = [(layer.weight.scale, layer.output_scale) for layer in self.children() if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)][:-1]\n",
        "\n",
        "        #print(self.fc3.bias.data)\n",
        "        self.fc3.bias.data = NetQuantizedWithBias.quantized_bias(\n",
        "            self.fc3.bias.data,\n",
        "            self.fc3.weight.scale,\n",
        "            self.input_scale,\n",
        "            preceding_scales\n",
        "        )\n",
        "        #print(self.fc3.bias.data)\n",
        "\n",
        "        if (self.fc3.bias.data < MIN_32B_SINT).any() or (self.fc3.bias.data > MAX_32B_SINT).any():\n",
        "            raise Exception(\"Bias has values which are out of bounds for an 32-bit signed integer\")\n",
        "        if (self.fc3.bias.data != self.fc3.bias.data.round()).any():\n",
        "            raise Exception(\"Bias has non-integer values\")\n",
        "\n",
        "    @staticmethod\n",
        "    def quantized_bias(bias: torch.Tensor, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]]) -> torch.Tensor:\n",
        "        '''\n",
        "        Quantize the bias so that all values are integers between MIN_32B_SINT and MAX_32B_SINT.\n",
        "\n",
        "        Parameters:\n",
        "        bias (Tensor): The floating point values of the bias\n",
        "        n_w (float): The scale by which the weights of this layer were multiplied\n",
        "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
        "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The bias in quantized form, where every value is an integer between MIN_32B_SINT and MAX_32B_SINT.\n",
        "                The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        return torch.clamp((bias * 2.5).round(), min=MIN_32B_SINT, max=MAX_32B_SINT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA6rXt3Q-zF8"
      },
      "source": [
        "net_quantized_with_bias = NetQuantizedWithBias(net_with_bias_with_quantized_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sLGGUTsr-NH"
      },
      "source": [
        "## Question 5.3:\n",
        "\n",
        "What is your accuracy before and after quantizing CNN with the bias?\n",
        "The accuracy change should ideally be negligible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJvR6Wv_GJJX"
      },
      "source": [
        "score = test(net_quantized_with_bias, testloader)\n",
        "print('Accuracy of the network on the test images after all the weights and the bias are quantized: {}%'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}